{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-6ODHz3eOx2"
   },
   "source": [
    "# ALX-ROBOTICS AI\n",
    "  This repository contains resources and projects related to Artificial Intelligence (AI) within the ALX Robotics program.\n",
    "\n",
    "  ## Overview\n",
    "\n",
    "  ALX Robotics offers a comprehensive curriculum encompassing various AI aspects including:\n",
    "\n",
    "  * **Machine Learning:** Supervised, unsupervised, and reinforcement learning algorithms.\n",
    "  * **Deep Learning:** Neural networks, convolutional neural networks (CNNs), recurrent neural networks (RNNs).\n",
    "  * **Computer Vision:** Image processing, object detection, and image classification.\n",
    "  * **Natural Language Processing (NLP):** Text analysis, language modeling, and sentiment analysis.\n",
    "  * **Robotics:** Integration of AI algorithms into robotic systems for autonomous navigation and manipulation.\n",
    "\n",
    "  ## Structure\n",
    "\n",
    "  The repository might include the following folders and files:\n",
    "\n",
    "  * **Projects:** Contains individual or group project folders, showcasing implemented AI solutions.\n",
    "  * **Datasets:** Contains pre-processed or raw data used for training AI models.\n",
    "  * **Documentation:** Provides information about the project, including design choices and implementation details.\n",
    "  * **Tutorials:** Contains example code and notebooks for different AI concepts and tools.\n",
    "  * **Libraries:** Contains custom Python libraries developed for the project.\n",
    "\n",
    "  ## Contributing\n",
    "\n",
    "  We welcome contributions from students, educators, and researchers.\n",
    "\n",
    "  **To contribute:**\n",
    "\n",
    "  1. Fork the repository.\n",
    "  2. Create a new branch for your contribution.\n",
    "  3. Commit your changes and push them to your branch.\n",
    "  4. Submit a pull request to the main branch.\n",
    "\n",
    "  ## License\n",
    "\n",
    "  This repository is licensed under the MIT License.\n",
    "\n",
    "\n",
    "  ## Contact\n",
    "\n",
    "  For any questions or inquiries, please contact [Your contact information]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MyId-HOeCVJ"
   },
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML PREDICTION & ANOMALIES DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0n9FiOBZdmr8"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "* DATA MONITORING & VISUALIZATION------------------\n",
    "*  # Devices:\n",
    "*     -> DHT22 sensor\n",
    "*     -> ESP32\n",
    "*  # Technologies:\n",
    "*     -> Protocol: HTTP\n",
    "*     -> Platform: ThingSpeak + Google Colab\n",
    "*  # Activity:\n",
    "*    -> Data transmission, monitoring and visualization\n",
    "*       - Single chart on Google Colab\n",
    "*\n",
    "*   ANGAZA ELIMU&ALX - IOT SCHOOL: Cohort 1, 2024\n",
    "* --------------------------------------------------\n",
    "'''\n",
    "\n",
    "'''\n",
    " Support libraries -------------------------------------------------------------\n",
    "'''\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from google.colab import userdata\n",
    "\n",
    "#---- ThingSpeak API details\n",
    "CHANNEL_ID = userdata.get('CHANNEL_ID')\n",
    "API_KEY = userdata.get('API_KEY') # Read API Key\n",
    "THINGSPEAK_URL = f\"https://api.thingspeak.com/channels/{CHANNEL_ID}/feeds.json?api_key={API_KEY}&results=100\"\n",
    "\n",
    "# ---- Fetch data from ThingSpeak\n",
    "response = requests.get(THINGSPEAK_URL)\n",
    "data = response.json()\n",
    "\n",
    "#---- Parse data\n",
    "timestamps = [entry['created_at'] for entry in data['feeds']]\n",
    "temperature = [float(entry['field1']) for entry in data['feeds']]\n",
    "humidity = [float(entry['field2']) for entry in data['feeds']]\n",
    "\n",
    "#---- Create DataFrame\n",
    "df = df.dropna()\n",
    "df = pd.DataFrame({'Timestamp': timestamps, 'Temperature': temperature, 'Humidity': humidity})\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "#---- Plot data\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df['Timestamp'], df['Temperature'], label='Temperature (°C)')\n",
    "plt.plot(df['Timestamp'], df['Humidity'], label='Humidity (%)')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Temperature and Humidity Monitoring')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML PREDICTION & ANOMALIES DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdSSBPwakhE3"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "* ML PREDICTION & ANOMALIES DETECTION ------------------\n",
    "*  # Devices:\n",
    "*     -> DHT22 sensor\n",
    "*     -> ESP32\n",
    "*  # Technologies:\n",
    "*     -> Protocol: HTTP\n",
    "*     -> Platform: ThingSpeak + Google Colab\n",
    "*     -> ML Tools: Prediction & Regression - LinearRegression\n",
    "*  # Activity:\n",
    "*    -> Using ML for data processing, prediction and anomalies detection\n",
    "*\n",
    "*   ANGAZA ELIMU&ALX - IOT SCHOOL: Cohort 1, 2024\n",
    "* --------------------------------------------------\n",
    "'''\n",
    "\n",
    "# Import necessary libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ThingSpeak Configuration\n",
    "CHANNEL_ID = userdata.get('CHANNEL_ID')\n",
    "READ_API_KEY = userdata.get('API_KEY') # Read API Key\n",
    "\n",
    "# Section 1: Data Collection from ThingSpeak\n",
    "def fetch_data():\n",
    "    url = f'https://api.thingspeak.com/channels/{CHANNEL_ID}/feeds.json?api_key={READ_API_KEY}&results=1000'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data['feeds'])\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['temperature'] = pd.to_numeric(df['field1'], errors='coerce')\n",
    "    df['humidity'] = pd.to_numeric(df['field2'], errors='coerce')\n",
    "    print(\"Data fetched successfully.\")\n",
    "    return df[['created_at', 'temperature', 'humidity']]\n",
    "\n",
    "# Section 2: Data Preparation\n",
    "def prepare_data(df):\n",
    "    df['time_index'] = (df['created_at'] - df['created_at'].min()).dt.total_seconds()\n",
    "    X = df[['time_index']]\n",
    "    y_temp = df['temperature']\n",
    "    y_hum = df['humidity']\n",
    "    print(\"Data prepared successfully.\")\n",
    "    return X, y_temp, y_hum\n",
    "\n",
    "# Section 3: Train Temperature and Humidity Prediction Models\n",
    "def train_regression_models(X, y_temp, y_hum):\n",
    "    # Split data for training and testing\n",
    "    X_train, X_test, y_temp_train, y_temp_test = train_test_split(X, y_temp, test_size=0.2, random_state=42)\n",
    "    _, _, y_hum_train, y_hum_test = train_test_split(X, y_hum, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train temperature prediction model\n",
    "    temp_model = LinearRegression()\n",
    "    temp_model.fit(X_train, y_temp_train)\n",
    "    temp_predictions = temp_model.predict(X_test)\n",
    "    temp_mse = mean_squared_error(y_temp_test, temp_predictions)\n",
    "\n",
    "    # Train humidity prediction model\n",
    "    hum_model = LinearRegression()\n",
    "    hum_model.fit(X_train, y_hum_train)\n",
    "    hum_predictions = hum_model.predict(X_test)\n",
    "    hum_mse = mean_squared_error(y_hum_test, hum_predictions)\n",
    "\n",
    "    print(f\"Temperature Prediction MSE: {temp_mse}\")\n",
    "    print(f\"Humidity Prediction MSE: {hum_mse}\")\n",
    "    return temp_model, hum_model\n",
    "\n",
    "# Section 4.1: Anomaly Detection for Humidity\n",
    "def humid_anomaly_detection(df):\n",
    "    hum_mean, hum_std = df['humidity'].mean(), df['humidity'].std()\n",
    "    threshold_upper = hum_mean + 2 * hum_std\n",
    "    threshold_lower = hum_mean - 2 * hum_std\n",
    "    df['humidity_anomaly'] = df['humidity'].apply(lambda x: 'Anomaly' if x > threshold_upper or x < threshold_lower else 'Normal')\n",
    "    print(\"Anomaly detection completed.\")\n",
    "    return threshold_upper, threshold_lower\n",
    "\n",
    "# Section 4.2: Anomaly Detection for Temperature\n",
    "def temp_anomaly_detection(df):\n",
    "    temp_mean, temp_std = df['temperature'].mean(), df['temperature'].std()\n",
    "    threshold_upper = temp_mean + 2 * temp_std\n",
    "    threshold_lower = temp_mean - 2 * temp_std\n",
    "    df['temperature_anomaly'] = df['temperature'].apply(lambda x: 'Anomaly' if x > threshold_upper or x < threshold_lower else 'Normal')\n",
    "    print(\"Anomaly detection completed.\")\n",
    "    return threshold_upper, threshold_lower\n",
    "\n",
    "# Section 5: Predict and Test on New Data\n",
    "def test_new_data(temp_model, hum_model, temp_thresholds, hum_thresholds):\n",
    "    # Fetch new data\n",
    "    new_data = fetch_data()\n",
    "    new_data['time_index'] = (new_data['created_at'] - new_data['created_at'].min()).dt.total_seconds()\n",
    "    X_new = new_data[['time_index']]\n",
    "\n",
    "    # Make predictions\n",
    "    new_data['predicted_temperature'] = temp_model.predict(X_new)\n",
    "    new_data['predicted_humidity'] = hum_model.predict(X_new)\n",
    "\n",
    "    # Apply anomaly detection for humidity\n",
    "    hum_upper, hum_lower = hum_thresholds\n",
    "    new_data['humidity_anomaly'] = new_data['humidity'].apply(lambda x: 'Anomaly' if x > hum_upper or x < hum_lower else 'Normal')\n",
    "\n",
    "    # Apply anomaly detection for temperature\n",
    "    temp_upper, temp_lower = temp_thresholds\n",
    "    new_data['temperature_anomaly'] = new_data['temperature'].apply(lambda x: 'Anomaly' if x > temp_upper or x < temp_lower else 'Normal')\n",
    "\n",
    "    print(\"Predictions and anomaly detection on new data:\")\n",
    "    print(new_data[['created_at', 'temperature', 'predicted_temperature', 'temperature_anomaly',\n",
    "                    'humidity', 'predicted_humidity', 'humidity_anomaly']].tail())\n",
    "\n",
    "# Main Execution Flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Fetch and prepare the data\n",
    "    df = fetch_data()\n",
    "    X, y_temp, y_hum = prepare_data(df)\n",
    "\n",
    "    # Step 2: Train the ML models for temperature and humidity\n",
    "    temp_model, hum_model = train_regression_models(X, y_temp, y_hum)\n",
    "\n",
    "    # Step 3: Set up and apply anomaly detection for humidity and temperature\n",
    "    temp_thresholds = temp_anomaly_detection(df)\n",
    "    hum_thresholds = humid_anomaly_detection(df)\n",
    "\n",
    "    # Step 4: Test and use the models on new data\n",
    "    test_new_data(temp_model, hum_model, temp_thresholds, hum_thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML CLASSIFICATION OF DATA TRENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_bhco8sqboD"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "* ML CLASSIFICATION OF DATA TRENDS ------------------\n",
    "*  # Devices:\n",
    "*     -> DHT22 sensor\n",
    "*     -> ESP32\n",
    "*  # Technologies:\n",
    "*     -> Protocol: HTTP\n",
    "*     -> Platform: ThingSpeak + Google Colab\n",
    "*     -> ML Tools: Data trends classification - RandomForestClassifier\n",
    "*  # Activity:\n",
    "*    -> Building a classification model to classify temperature trends (e.g., \"Rising\", \"Falling\", or \"Stable\")\n",
    "*       based on the dataset collected from a DHT22 sensor.\n",
    "*\n",
    "*   ANGAZA ELIMU&ALX - IOT SCHOOL: Cohort 1, 2024\n",
    "* --------------------------------------------------\n",
    "'''\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ThingSpeak Configuration\n",
    "CHANNEL_ID = userdata.get('CHANNEL_ID')\n",
    "READ_API_KEY = userdata.get('API_KEY') # Read API Key\n",
    "\n",
    "# Section 1: Data Collection from ThingSpeak\n",
    "def fetch_data():\n",
    "    \"\"\"\n",
    "    Fetches temperature and humidity data from a ThingSpeak channel.\n",
    "    Returns a DataFrame with timestamp, temperature, and humidity columns.\n",
    "    \"\"\"\n",
    "    url = f'https://api.thingspeak.com/channels/{CHANNEL_ID}/feeds.json?api_key={READ_API_KEY}&results=1000'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data['feeds'])\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['temperature'] = pd.to_numeric(df['field1'], errors='coerce')\n",
    "    df['humidity'] = pd.to_numeric(df['field2'], errors='coerce')\n",
    "    print(\"Data fetched successfully.\")\n",
    "    return df[['created_at', 'temperature', 'humidity']]\n",
    "\n",
    "# Section 2: Preprocess and label data for trends\n",
    "def label_temperature_trends(df):\n",
    "    \"\"\"\n",
    "    Label temperature trends:\n",
    "    - Rising: if temperature at t > temperature at t-1\n",
    "    - Falling: if temperature at t < temperature at t-1\n",
    "    - Stable: if temperature at t == temperature at t-1\n",
    "    \"\"\"\n",
    "    df['temperature_diff'] = df['temperature'].diff()\n",
    "    df['trend'] = df['temperature_diff'].apply(\n",
    "        lambda x: 'Rising' if x > 0 else ('Falling' if x < 0 else 'Stable')\n",
    "    )\n",
    "    df = df.dropna()  # Drop the first row since it will have NaN for diff\n",
    "    print(\"Temperature trends labeled successfully.\")\n",
    "    return df\n",
    "\n",
    "# Section 3: Split data into features and labels\n",
    "def prepare_data(df):\n",
    "    # Features: Use time-based index and previous temperature values\n",
    "    df['time_index'] = (df['created_at'] - df['created_at'].min()).dt.total_seconds()\n",
    "    X = df[['time_index', 'temperature']]\n",
    "    y = df['trend']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Section 4: Train a classification model\n",
    "def train_classification_model(X_train, y_train):\n",
    "    clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Classification model trained successfully.\")\n",
    "    return clf\n",
    "\n",
    "# Section 5: Test and evaluate the model\n",
    "def evaluate_model(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    return y_pred\n",
    "\n",
    "# Section 6: Visualize classification results\n",
    "def visualize_results(df, y_pred, X_test):\n",
    "    df_test = pd.DataFrame(X_test)\n",
    "    df_test['predicted_trend'] = y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for trend in df_test['predicted_trend'].unique():\n",
    "        subset = df_test[df_test['predicted_trend'] == trend]\n",
    "        plt.scatter(subset['time_index'], subset['temperature'], label=trend)\n",
    "    plt.xlabel(\"Time Index\")\n",
    "    plt.ylabel(\"Temperature\")\n",
    "    plt.title(\"Temperature Trend Classification\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Section 7: Predict and classify trends on new data\n",
    "def classify_new_data(clf):\n",
    "    new_data = fetch_data()\n",
    "    new_data['time_index'] = (new_data['created_at'] - new_data['created_at'].min()).dt.total_seconds()\n",
    "    X_new = new_data[['time_index', 'temperature']]\n",
    "    new_data['predicted_trend'] = clf.predict(X_new)\n",
    "    print(\"Predicted trends on new data:\")\n",
    "    print(new_data[['created_at', 'temperature', 'predicted_trend']].tail())\n",
    "    return new_data\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Fetch and preprocess the data\n",
    "    df = fetch_data()\n",
    "    df = label_temperature_trends(df)\n",
    "\n",
    "    # Step 2: Split the data\n",
    "    X_train, X_test, y_train, y_test = prepare_data(df)\n",
    "\n",
    "    # Step 3: Train the classification model\n",
    "    clf = train_classification_model(X_train, y_train)\n",
    "\n",
    "    # Step 4: Evaluate the model\n",
    "    y_pred = evaluate_model(clf, X_test, y_test)\n",
    "\n",
    "    # Step 5: Visualize classification results\n",
    "    visualize_results(df, y_pred, X_test)\n",
    "\n",
    "    # Step 6: Predict on new data\n",
    "    classify_new_data(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCdve7Udqxkn"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "* DATA MONITORING & VISUALIZATION------------------\n",
    "*  # Devices:\n",
    "*     -> DHT22 sensor\n",
    "*     -> ESP32\n",
    "*  # Technologies:\n",
    "*     -> Protocol: HTTP\n",
    "*     -> Platform: ThingSpeak + Google Colab\n",
    "*  # Activity:\n",
    "*    -> Data transmission, monitoring and visualization\n",
    "*       - Anomalies detection in temperature&humidity data trends\n",
    "*\n",
    "*   ANGAZA ELIMU&ALX - IOT SCHOOL: Cohort 1, 2024\n",
    "* --------------------------------------------------\n",
    "'''\n",
    "\n",
    "'''\n",
    " Support libraries -------------------------------------------------------------\n",
    "'''\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- ThingSpeak API details\n",
    "CHANNEL_ID = userdata.get('CHANNEL_ID')\n",
    "READ_API_KEY = userdata.get('API_KEY') # Read API Key\n",
    "THINGSPEAK_URL = f\"https://api.thingspeak.com/channels/{CHANNEL_ID}/feeds.json?api_key={API_KEY}&results=100\"\n",
    "\n",
    "# ---- Fetch data from ThingSpeak\n",
    "response = requests.get(THINGSPEAK_URL)\n",
    "data = response.json()\n",
    "\n",
    "# ---- Extract data\n",
    "timestamps = [entry['created_at'] for entry in data['feeds']]\n",
    "temperature = [float(entry['field1']) for entry in data['feeds']]\n",
    "humidity = [float(entry['field2']) for entry in data['feeds']]\n",
    "\n",
    "# ---- Dataframe setup\n",
    "df = df.dropna()\n",
    "df = pd.DataFrame({'Timestamp': timestamps, 'Temperature': temperature, 'Humidity': humidity})\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "# ---- Anomaly thresholds definition\n",
    "# compute the average mean and std deviation\n",
    "temp_mean, temp_std = np.mean(df['Temperature']), np.std(df['Temperature'])\n",
    "hum_mean, hum_std = np.mean(df['Humidity']), np.std(df['Humidity'])\n",
    "\n",
    "# define lower and upper limit thresholds\n",
    "temp_threshold_upper = temp_mean + 2 * temp_std\n",
    "temp_threshold_lower = temp_mean - 2 * temp_std\n",
    "hum_threshold_upper = hum_mean + 2 * hum_std\n",
    "hum_threshold_lower = hum_mean - 2 * hum_std\n",
    "\n",
    "# ---- Flag anomalies\n",
    "df['Temp_Anomaly'] = (df['Temperature'] > temp_threshold_upper) | (df['Temperature'] < temp_threshold_lower)\n",
    "df['Hum_Anomaly'] = (df['Humidity'] > hum_threshold_upper) | (df['Humidity'] < hum_threshold_lower)\n",
    "\n",
    "# ---- Plot data and anomalies\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# ---- Plot temperature data with mean and threshold lines\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(df['Timestamp'], df['Temperature'], label='Temperature', color='blue')\n",
    "plt.axhline(temp_mean, color='green', linestyle='--', label='Temperature Mean')\n",
    "plt.axhline(temp_threshold_upper, color='red', linestyle='--', label='Temperature Upper Threshold')\n",
    "plt.axhline(temp_threshold_lower, color='orange', linestyle='--', label='Temperature Lower Threshold')\n",
    "plt.scatter(df[df['Temp_Anomaly']]['Timestamp'], df[df['Temp_Anomaly']]['Temperature'], color='red', label='Temperature Anomaly', s=50, zorder=5)\n",
    "plt.fill_between(df['Timestamp'], temp_threshold_lower, temp_threshold_upper, color='lightblue', alpha=0.1, label='Normal Temperature Range')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Anomaly Detection in Temperature')\n",
    "\n",
    "# ---- Plot humidity data with mean and threshold lines\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(df['Timestamp'], df['Humidity'], label='Humidity', color='purple')\n",
    "plt.axhline(hum_mean, color='green', linestyle='--', label='Humidity Mean')\n",
    "plt.axhline(hum_threshold_upper, color='red', linestyle='--', label='Humidity Upper Threshold')\n",
    "plt.axhline(hum_threshold_lower, color='orange', linestyle='--', label='Humidity Lower Threshold')\n",
    "plt.scatter(df[df['Hum_Anomaly']]['Timestamp'], df[df['Hum_Anomaly']]['Humidity'], color='purple', label='Humidity Anomaly', s=50, zorder=5)\n",
    "plt.fill_between(df['Timestamp'], hum_threshold_lower, hum_threshold_upper, color='lightgreen', alpha=0.1, label='Normal Humidity Range')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Humidity (%)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Anomaly Detection in Humidity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmcKts66v0-T"
   },
   "source": [
    "# DATA MONITORING & VISUALIZATION | PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRNaUZD-rRBk"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "* DATA MONITORING & VISUALIZATION------------------\n",
    "*  # Devices:\n",
    "*     -> DHT22 sensor\n",
    "*     -> ESP32\n",
    "*  # Technologies:\n",
    "*     -> Protocol: HTTP\n",
    "*     -> Platform: ThingSpeak + Google Colab\n",
    "*  # Activity:\n",
    "*    -> Data transmission, monitoring and visualization\n",
    "*       - Time series basic weather forecasting and prediction\n",
    "*\n",
    "*   ANGAZA ELIMU&ALX - IOT SCHOOL: Cohort 1, 2024\n",
    "* --------------------------------------------------\n",
    "'''\n",
    "\n",
    "'''\n",
    " Support libraries -------------------------------------------------------------\n",
    "'''\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "\n",
    "# ---- ThingSpeak API details\n",
    "CHANNEL_ID = userdata.get('CHANNEL_ID')\n",
    "READ_API_KEY = userdata.get('API_KEY') # Read API Key\n",
    "THINGSPEAK_URL = f\"https://api.thingspeak.com/channels/{CHANNEL_ID}/feeds.json?api_key={API_KEY}&results=100\"\n",
    "\n",
    "# ---- Fetch data from ThingSpeak\n",
    "response = requests.get(THINGSPEAK_URL)\n",
    "data = response.json()\n",
    "\n",
    "# ---- Parse data\n",
    "timestamps = [entry['created_at'] for entry in data['feeds']]\n",
    "temperature = [float(entry['field1']) for entry in data['feeds']]\n",
    "humidity = [float(entry['field2']) for entry in data['feeds']]\n",
    "\n",
    "# ---- Create DataFrame\n",
    "df = df.dropna()\n",
    "df = pd.DataFrame({'Timestamp': timestamps, 'Temperature': temperature, 'Humidity': humidity})\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "# ---- Prepare data for Prophet - the future forecasting handler lib\n",
    "temperature_df = df[['Timestamp', 'Temperature']].rename(columns={'Timestamp': 'ds', 'Temperature': 'y'})\n",
    "humidity_df = df[['Timestamp', 'Humidity']].rename(columns={'Timestamp': 'ds', 'Humidity': 'y'})\n",
    "\n",
    "# ---- Remove timezone from 'ds' column - timezone not required for the prophet future forecasting lib handler lib\n",
    "temperature_df['ds'] = temperature_df['ds'].dt.tz_localize(None)\n",
    "humidity_df['ds'] = humidity_df['ds'].dt.tz_localize(None)\n",
    "\n",
    "# ---- Fit Prophet model for Temperature Forecasting\n",
    "temp_model = Prophet(interval_width=0.95)  # Set prediction interval to 95%\n",
    "temp_model.fit(temperature_df)\n",
    "\n",
    "# ---- Forecasting 24 hours into the future\n",
    "future_temp = temp_model.make_future_dataframe(periods=24, freq='h')\n",
    "temp_forecast = temp_model.predict(future_temp)\n",
    "\n",
    "# ---- Plot Temperature Forecast\n",
    "plt.figure(figsize=(10, 5))\n",
    "temp_model.plot(temp_forecast, xlabel='Time', ylabel='Temperature (°C)')\n",
    "plt.title('24-Hour Temperature Forecast with Historical Trends')\n",
    "plt.grid(True)\n",
    "\n",
    "# ---- Highlight observed data period\n",
    "plt.fill_between(temp_forecast['ds'], temp_forecast['yhat_lower'], temp_forecast['yhat_upper'], color='skyblue', alpha=0.2)\n",
    "plt.annotate('Future Predicted Range', xy=(temp_forecast['ds'].iloc[-5], temp_forecast['yhat'].iloc[-5]), color='blue')\n",
    "\n",
    "# ---- Fit Prophet model for Humidity Forecasting\n",
    "humidity_model = Prophet(interval_width=0.95)\n",
    "humidity_model.fit(humidity_df)\n",
    "\n",
    "# ---- Forecasting 24 hours into the future\n",
    "future_humidity = humidity_model.make_future_dataframe(periods=24, freq='h')\n",
    "humidity_forecast = humidity_model.predict(future_humidity)\n",
    "\n",
    "# ---- Plot Humidity Forecast\n",
    "plt.figure(figsize=(10, 5))\n",
    "humidity_model.plot(humidity_forecast, xlabel='Time', ylabel='Humidity (%)')\n",
    "plt.title('24-Hour Humidity Forecast with Historical Trends')\n",
    "plt.grid(True)\n",
    "\n",
    "# ---- Highlight observed data period\n",
    "plt.fill_between(humidity_forecast['ds'], humidity_forecast['yhat_lower'], humidity_forecast['yhat_upper'], color='lightgreen', alpha=0.2)\n",
    "plt.annotate('Future Predicted Range', xy=(humidity_forecast['ds'].iloc[-5], humidity_forecast['yhat'].iloc[-5]), color='green')\n",
    "\n",
    "# ---- Plot the forecast\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VApq2d65vma0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHOsWtSxviTl"
   },
   "source": [
    "# ML PREDICTION & ANOMALIES DETECTION | DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ht6RhMS4vXtT"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "* ML PREDICTION & ANOMALIES DETECTION ------------------\n",
    "*  # Devices:\n",
    "*     -> DHT22 sensor\n",
    "*     -> ESP32\n",
    "*  # Technologies:\n",
    "*     -> Protocol: HTTP\n",
    "*     -> Platform: ThingSpeak + Google Colab\n",
    "*     -> ML Tools: Prediction & Regression - LinearRegression\n",
    "*  # Activity:\n",
    "*    -> Using ML for data processing, prediction and anomalies detection\n",
    "*\n",
    "*   ANGAZA ELIMU&ALX - IOT SCHOOL: Cohort 1, 2024\n",
    "* --------------------------------------------------\n",
    "'''\n",
    "\n",
    "# Import necessary libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ThingSpeak Configuration\n",
    "CHANNEL_ID = userdata.get('CHANNEL_ID')\n",
    "READ_API_KEY = userdata.get('API_KEY') # Read API Key\n",
    "\n",
    "# Section 1: Data Collection from ThingSpeak\n",
    "def fetch_data():\n",
    "    url = f'https://api.thingspeak.com/channels/{CHANNEL_ID}/feeds.json?api_key={READ_API_KEY}&results=1000'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data['feeds'])\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['temperature'] = pd.to_numeric(df['field1'], errors='coerce')\n",
    "    df['humidity'] = pd.to_numeric(df['field2'], errors='coerce')\n",
    "    print(\"Data fetched successfully.\")\n",
    "    return df[['created_at', 'temperature', 'humidity']]\n",
    "\n",
    "# Section 2: Data Preparation\n",
    "def prepare_data(df):\n",
    "    df['time_index'] = (df['created_at'] - df['created_at'].min()).dt.total_seconds()\n",
    "    X = df[['time_index']]\n",
    "    y_temp = df['temperature']\n",
    "    y_hum = df['humidity']\n",
    "    print(\"Data prepared successfully.\")\n",
    "    return X, y_temp, y_hum\n",
    "\n",
    "# Section 3: Train Temperature and Humidity Prediction Models\n",
    "def train_regression_models(X, y_temp, y_hum):\n",
    "    # Split data for training and testing\n",
    "    X_train, X_test, y_temp_train, y_temp_test = train_test_split(X, y_temp, test_size=0.2, random_state=42)\n",
    "    _, _, y_hum_train, y_hum_test = train_test_split(X, y_hum, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train temperature prediction model\n",
    "    temp_model = LinearRegression()\n",
    "    temp_model.fit(X_train, y_temp_train)\n",
    "    temp_predictions = temp_model.predict(X_test)\n",
    "    temp_mse = mean_squared_error(y_temp_test, temp_predictions)\n",
    "\n",
    "    # Train humidity prediction model\n",
    "    hum_model = LinearRegression()\n",
    "    hum_model.fit(X_train, y_hum_train)\n",
    "    hum_predictions = hum_model.predict(X_test)\n",
    "    hum_mse = mean_squared_error(y_hum_test, hum_predictions)\n",
    "\n",
    "    print(f\"Temperature Prediction MSE: {temp_mse}\")\n",
    "    print(f\"Humidity Prediction MSE: {hum_mse}\")\n",
    "    return temp_model, hum_model\n",
    "\n",
    "# Section 4.1: Anomaly Detection for Humidity\n",
    "def humid_anomaly_detection(df):\n",
    "    hum_mean, hum_std = df['humidity'].mean(), df['humidity'].std()\n",
    "    threshold_upper = hum_mean + 2 * hum_std\n",
    "    threshold_lower = hum_mean - 2 * hum_std\n",
    "    df['humidity_anomaly'] = df['humidity'].apply(lambda x: 'Anomaly' if x > threshold_upper or x < threshold_lower else 'Normal')\n",
    "    print(\"Anomaly detection completed.\")\n",
    "    return threshold_upper, threshold_lower\n",
    "\n",
    "# Section 4.2: Anomaly Detection for Temperature\n",
    "def temp_anomaly_detection(df):\n",
    "    temp_mean, temp_std = df['temperature'].mean(), df['temperature'].std()\n",
    "    threshold_upper = temp_mean + 2 * temp_std\n",
    "    threshold_lower = temp_mean - 2 * temp_std\n",
    "    df['temperature_anomaly'] = df['temperature'].apply(lambda x: 'Anomaly' if x > threshold_upper or x < threshold_lower else 'Normal')\n",
    "    print(\"Anomaly detection completed.\")\n",
    "    return threshold_upper, threshold_lower\n",
    "\n",
    "# Section 5: Predict and Test on New Data\n",
    "def test_new_data(temp_model, hum_model, temp_thresholds, hum_thresholds):\n",
    "    # Fetch new data\n",
    "    new_data = fetch_data()\n",
    "    new_data['time_index'] = (new_data['created_at'] - new_data['created_at'].min()).dt.total_seconds()\n",
    "    X_new = new_data[['time_index']]\n",
    "\n",
    "    # Make predictions\n",
    "    new_data['predicted_temperature'] = temp_model.predict(X_new)\n",
    "    new_data['predicted_humidity'] = hum_model.predict(X_new)\n",
    "\n",
    "    # Apply anomaly detection for humidity\n",
    "    hum_upper, hum_lower = hum_thresholds\n",
    "    new_data['humidity_anomaly'] = new_data['humidity'].apply(lambda x: 'Anomaly' if x > hum_upper or x < hum_lower else 'Normal')\n",
    "\n",
    "    # Apply anomaly detection for temperature\n",
    "    temp_upper, temp_lower = temp_thresholds\n",
    "    new_data['temperature_anomaly'] = new_data['temperature'].apply(lambda x: 'Anomaly' if x > temp_upper or x < temp_lower else 'Normal')\n",
    "\n",
    "    print(\"Predictions and anomaly detection on new data:\")\n",
    "    print(new_data[['created_at', 'temperature', 'predicted_temperature', 'temperature_anomaly',\n",
    "                    'humidity', 'predicted_humidity', 'humidity_anomaly']].tail())\n",
    "\n",
    "# Main Execution Flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Fetch and prepare the data\n",
    "    df = fetch_data()\n",
    "    X, y_temp, y_hum = prepare_data(df)\n",
    "\n",
    "    # Step 2: Train the ML models for temperature and humidity\n",
    "    temp_model, hum_model = train_regression_models(X, y_temp, y_hum)\n",
    "\n",
    "    # Step 3: Set up and apply anomaly detection for humidity and temperature\n",
    "    temp_thresholds = temp_anomaly_detection(df)\n",
    "    hum_thresholds = humid_anomaly_detection(df)\n",
    "\n",
    "    # Step 4: Test and use the models on new data\n",
    "    test_new_data(temp_model, hum_model, temp_thresholds, hum_thresholds)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
